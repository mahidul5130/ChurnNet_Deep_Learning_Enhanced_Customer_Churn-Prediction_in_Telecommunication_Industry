{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7T0XVu1QDS",
        "outputId": "cf07c675-c9e0-4a7d-9e05-6b7c8e351b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2BoEFIVyPEe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Add\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.layers import Conv1D, Activation, Multiply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ftaVm2vvyth"
      },
      "outputs": [],
      "source": [
        "df_raw = pd.read_csv(\"IBM Telco Dataset (7043).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AZDaE4DLVcq"
      },
      "outputs": [],
      "source": [
        "df_raw.loc[df_raw[\"MultipleLines\"] == \"No phone service\", \"MultipleLines\"] = 'No'\n",
        "df_raw.loc[df_raw[\"OnlineSecurity\"] == \"No internet service\", \"OnlineSecurity\"] = 'No'\n",
        "df_raw.loc[df_raw[\"OnlineBackup\"] == \"No internet service\", \"OnlineBackup\"] = 'No'\n",
        "df_raw.loc[df_raw[\"DeviceProtection\"] == \"No internet service\", \"DeviceProtection\"] = 'No'\n",
        "df_raw.loc[df_raw[\"TechSupport\"] == \"No internet service\", \"TechSupport\"] = 'No'\n",
        "df_raw.loc[df_raw[\"StreamingTV\"] == \"No internet service\", \"StreamingTV\"] = 'No'\n",
        "df_raw.loc[df_raw[\"StreamingMovies\"] == \"No internet service\", \"StreamingMovies\"] = 'No'\n",
        "df_raw.loc[df_raw[\"DeviceProtection\"] == \"No internet service\", \"DeviceProtection\"] = 'No'\n",
        "df_raw.loc[df_raw[\"TotalCharges\"] == \" \", \"TotalCharges\"] = '0'\n",
        "df_raw['TotalCharges'] = pd.to_numeric(df_raw['TotalCharges'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DYXdsCzQs2o"
      },
      "outputs": [],
      "source": [
        "# Encoder = \"Label Encoder\"\n",
        "Encoder = \"Label Encoder\"\n",
        "# OverSamplingTecnique = \"\"\n",
        "OverSamplingTecnique = \"SMOTE-Enn\"\n",
        "# OverSamplingTecnique = \"SMOTE-Tomek\"\n",
        "# OverSamplingTecnique = \"SMOTE-Enn\"\n",
        "filter_size=5\n",
        "number_of_filter=128\n",
        "flatten_layer_exist=True\n",
        "Model_Name=\"SE Block\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYrRuOWWDlGt"
      },
      "source": [
        "**Label Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeJgfRf2zQ8N",
        "outputId": "8f94d127-0e7c-4a5d-f85c-c11fba6b4289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying Label Encoder\n",
            "Label Encoder Transformation\n",
            "gender  :  [0 1]  =  ['Female' 'Male']\n",
            "SeniorCitizen  :  [0 1]  =  [0 1]\n",
            "Partner  :  [1 0]  =  ['Yes' 'No']\n",
            "Dependents  :  [0 1]  =  ['No' 'Yes']\n",
            "PhoneService  :  [0 1]  =  ['No' 'Yes']\n",
            "MultipleLines  :  [0 1]  =  ['No' 'Yes']\n",
            "InternetService  :  [0 1 2]  =  ['DSL' 'Fiber optic' 'No']\n",
            "OnlineSecurity  :  [0 1]  =  ['No' 'Yes']\n",
            "OnlineBackup  :  [1 0]  =  ['Yes' 'No']\n",
            "DeviceProtection  :  [0 1]  =  ['No' 'Yes']\n",
            "TechSupport  :  [0 1]  =  ['No' 'Yes']\n",
            "StreamingTV  :  [0 1]  =  ['No' 'Yes']\n",
            "StreamingMovies  :  [0 1]  =  ['No' 'Yes']\n",
            "Contract  :  [0 1 2]  =  ['Month-to-month' 'One year' 'Two year']\n",
            "PaperlessBilling  :  [1 0]  =  ['Yes' 'No']\n",
            "PaymentMethod  :  [2 3 0 1]  =  ['Electronic check' 'Mailed check' 'Bank transfer (automatic)'\n",
            " 'Credit card (automatic)']\n",
            "Churn  :  [0 1]  =  ['No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "if Encoder == \"Label Encoder\":\n",
        "  print(\"Applying Label Encoder\")\n",
        "  df_final = df_raw.copy()\n",
        "  le = LabelEncoder()\n",
        "\n",
        "  text_data_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
        "              'InternetService','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "              'StreamingTV', 'StreamingMovies', 'Contract','PaperlessBilling', 'PaymentMethod', 'Churn']\n",
        "\n",
        "  print('Label Encoder Transformation')\n",
        "  for i in text_data_features :\n",
        "      df_final[i] = le.fit_transform(df_final[i])\n",
        "      print(i,' : ',df_final[i].unique(),' = ',le.inverse_transform(df_final[i].unique()))\n",
        "\n",
        "\n",
        "\n",
        "  X = df_final.drop(['Churn','customerID'], axis=1).copy()\n",
        "  Y = df_final['Churn'].copy().astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ane99tYEIOh"
      },
      "source": [
        "**One-hot Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dv3ldE80D3ZE"
      },
      "outputs": [],
      "source": [
        "if Encoder == \"One-hot Encoder\":\n",
        "  print(\"Applying One-hot Encoder\")\n",
        "\n",
        "  # One-hot encode categorical columns\n",
        "  categorical_columns = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
        "              'InternetService','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "              'StreamingTV', 'StreamingMovies', 'Contract','PaperlessBilling', 'PaymentMethod']\n",
        "\n",
        "  encoder = OneHotEncoder()\n",
        "  encoded_features = encoder.fit_transform(df_raw[categorical_columns]).toarray()\n",
        "\n",
        "  # Combine one-hot encoded features with numerical features\n",
        "  numerical_features = df_raw.drop(categorical_columns + ['Churn', 'customerID'], axis=1)\n",
        "  X = np.hstack((encoded_features, numerical_features))\n",
        "\n",
        "  # Manually encode 'Churn' column\n",
        "  df_raw['Churn'] = df_raw['Churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
        "  # Extract the target variable Y\n",
        "  Y = df_raw['Churn'].values\n",
        "\n",
        "\n",
        "  # Ensure all data is in float format\n",
        "  X = X.astype(float)\n",
        "  Y = Y.astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-BpjVzpDism"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_resampled_scaled = scaler.fit_transform(X)\n",
        "X=X_resampled_scaled\n",
        "Y=Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7pIpuVLkAtY"
      },
      "source": [
        "**SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMjsybEwWoKM"
      },
      "outputs": [],
      "source": [
        "if OverSamplingTecnique == \"SMOTE\":\n",
        "  print(\"Applying SMOTE\")\n",
        "  smote = SMOTE()\n",
        "\n",
        "  X_resampled, y_resampled = smote.fit_resample(X, Y)\n",
        "  scaler = StandardScaler()\n",
        "  X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "  X=X_resampled_scaled\n",
        "  Y=y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jVA_s6eWqY8"
      },
      "source": [
        "**SMOTETomek**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7oiJql-MBfp"
      },
      "outputs": [],
      "source": [
        "if OverSamplingTecnique == \"SMOTE-Tomek\":\n",
        "  print(\"Applying SMOTE-Tomek\")\n",
        "\n",
        "  smote_tomek = SMOTETomek()\n",
        "  X_resampled, y_resampled = smote_tomek.fit_resample(X, Y)\n",
        "  scaler = StandardScaler()\n",
        "  X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "  X=X_resampled_scaled\n",
        "  Y=y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyUdGscLL53Y"
      },
      "source": [
        "**SMOTEENN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jUMKlEazjOF",
        "outputId": "354b0123-b69c-4fd4-89f5-68cbc4dd0018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying SMOTE-Enn\n"
          ]
        }
      ],
      "source": [
        "if OverSamplingTecnique == \"SMOTE-Enn\":\n",
        "  print(\"Applying SMOTE-Enn\")\n",
        "\n",
        "  smote_enn = SMOTEENN()\n",
        "  X_resampled, y_resampled = smote_enn.fit_resample(X, Y)\n",
        "  scaler = StandardScaler()\n",
        "  X_resampled_scaled = scaler.fit_transform(X_resampled)\n",
        "  X=X_resampled_scaled\n",
        "  Y=y_resampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgY86usCiVaw"
      },
      "source": [
        "**Squeeze-and-Excitation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z__CRDfozaXN"
      },
      "outputs": [],
      "source": [
        "# Define the channel attention layer\n",
        "class ChannelAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, reduction_ratio=8):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        channels = input_shape[-1]\n",
        "        self.fc = tf.keras.layers.Dense(channels // self.reduction_ratio, activation='relu')\n",
        "        self.attention = tf.keras.layers.Dense(channels, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = tf.reduce_mean(inputs, axis=[1])  # Global average pooling across time dimension\n",
        "        x = self.fc(x)\n",
        "        x = self.attention(x)\n",
        "        x = tf.expand_dims(x, axis=1)  # Add a new dimension for broadcasting\n",
        "        return inputs * x\n",
        "\n",
        "# Define the spatial attention layer\n",
        "class SpatialAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.max_pool = tf.keras.layers.MaxPooling1D(pool_size=3, strides=1, padding='same')\n",
        "        self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size=3, strides=1, padding='same')\n",
        "        self.concat = tf.keras.layers.Concatenate(axis=-1)\n",
        "        self.conv1d = tf.keras.layers.Conv1D(filters=1, kernel_size=3, padding='same', activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        max_pool_out = self.max_pool(inputs)\n",
        "        avg_pool_out = self.avg_pool(inputs)\n",
        "        concat_out = self.concat([max_pool_out, avg_pool_out])\n",
        "        attention_weights = self.conv1d(concat_out)\n",
        "        return inputs * attention_weights\n",
        "\n",
        "\n",
        "# Define the residual block\n",
        "def residual_block(x, filters, kernel_size):\n",
        "    # Save the input tensor\n",
        "    x_shortcut = x\n",
        "\n",
        "    # First convolutional layer\n",
        "    x = tf.keras.layers.Conv1D(filters, kernel_size, activation='relu', padding='same')(x)\n",
        "\n",
        "    # Second convolutional layer\n",
        "    x = tf.keras.layers.Conv1D(filters, kernel_size, activation='relu', padding='same')(x)\n",
        "\n",
        "    # Add the shortcut connection\n",
        "    x = Add()([x, x_shortcut])\n",
        "\n",
        "    # Apply ReLU activation\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s15-s2sHiZZz"
      },
      "source": [
        "**Basic Channel Attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8noScGii6qe"
      },
      "outputs": [],
      "source": [
        "# Define the channel attention layer for 1D data\n",
        "class Basic_ChannelAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, ratio=8):\n",
        "        super(Basic_ChannelAttention, self).__init__()\n",
        "        self.ratio = ratio\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, channels = input_shape[1:]\n",
        "        self.shared_layer1 = Conv1D(channels // self.ratio, kernel_size=1, activation='relu', padding='same')\n",
        "        self.shared_layer2 = Conv1D(channels, kernel_size=1, padding='same')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x1 = tf.reduce_mean(inputs, axis=1, keepdims=True)\n",
        "        x1 = self.shared_layer1(x1)\n",
        "        x1 = self.shared_layer2(x1)\n",
        "\n",
        "        x2 = tf.reduce_max(inputs, axis=1, keepdims=True)\n",
        "        x2 = self.shared_layer1(x2)\n",
        "        x2 = self.shared_layer2(x2)\n",
        "\n",
        "        attention = tf.add(x1, x2)\n",
        "        attention = Activation(\"sigmoid\")(attention)\n",
        "        output = Multiply()([inputs, attention])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9uxxru9zgU1"
      },
      "outputs": [],
      "source": [
        "def kfold(filter_size, number_of_filter, flatten_layer_exist, Model_Name):\n",
        "  print(\"Applying K-fold\")\n",
        "  print(f\"Applying {number_of_filter} filters of size {filter_size}\")\n",
        "\n",
        "\n",
        "  # Assuming X and Y are your input and target data\n",
        "  # Define the number of folds\n",
        "  num_folds = 10\n",
        "\n",
        "  # Initialize lists to store the evaluation results\n",
        "  accuracy_scores = []\n",
        "  precision_scores = []\n",
        "  recall_scores = []\n",
        "  f1_scores = []\n",
        "  mcc_scores = []\n",
        "  auc_roc_scores = []\n",
        "\n",
        "\n",
        "\n",
        "  # Perform stratified k-fold cross-validation\n",
        "  fold_number = 1  # Initialize the fold number\n",
        "  skf = StratifiedKFold(n_splits=num_folds, shuffle=True)\n",
        "  for train_index, test_index in skf.split(X, Y):\n",
        "      print(f\"Fold {fold_number}/{num_folds}:\")\n",
        "      # Split the data into training and test sets for the current fold\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      # X_train, X_test = X[train_index], X[test_index]\n",
        "      Y_train, Y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "      # Create the model with attention mechanisms and residual blocks\n",
        "      inputs = tf.keras.Input(shape=(X_train.shape[1], 1))\n",
        "      x = tf.keras.layers.Conv1D(filters=number_of_filter, kernel_size=filter_size, activation='relu')(inputs)\n",
        "      x_res = residual_block(x, number_of_filter, filter_size)  # Apply the first residual block\n",
        "      if Model_Name == \"SE Block\":\n",
        "        print(\"Applying SE Block\")\n",
        "        x = ChannelAttention()(x_res)  # Apply channel attention\n",
        "      else:\n",
        "        print(\"Applying Basic Channel Attenntion\")\n",
        "        x = Basic_ChannelAttention()(x_res)  # Apply channel attention\n",
        "      x = SpatialAttention()(x)  # Apply spatial attention\n",
        "      x = tf.keras.layers.Conv1D(filters=number_of_filter, kernel_size=filter_size, activation='relu', padding='same')(x)\n",
        "      x_res = residual_block(x, number_of_filter, filter_size)  # Apply the second residual block\n",
        "      if Model_Name == \"SE Block\":\n",
        "        print(\"Applying SE Block\")\n",
        "        x = ChannelAttention()(x_res)  # Apply channel attention\n",
        "      else:\n",
        "        print(\"Applying Basic Channel Attenntion\")\n",
        "        x = Basic_ChannelAttention()(x_res)  # Apply channel attention\n",
        "      x = SpatialAttention()(x)  # Apply spatial attention\n",
        "      if flatten_layer_exist==True:\n",
        "        print(\"Applying flatten layer\")\n",
        "        x = tf.keras.layers.Flatten()(x)  # Flatten the output before dense layers\n",
        "      else:\n",
        "        print(\"Applying Globale Max Pooling 1D layer\")\n",
        "        x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
        "      x = tf.keras.layers.Dropout(0.5)(x)\n",
        "      x = tf.keras.layers.Dense(number_of_filter, activation='relu')(x)\n",
        "      outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "      model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "      # Compile and train the model\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "      model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "      model.fit(X_train, Y_train, epochs=30, batch_size=32, verbose=\"1\",validation_split=0.2)\n",
        "      # Evaluate the model on the test set\n",
        "      Y_pred = model.predict(X_test)\n",
        "      Y_pred_binary = np.round(Y_pred).flatten()\n",
        "\n",
        "      # Calculate evaluation metrics\n",
        "      accuracy = accuracy_score(Y_test, Y_pred_binary)\n",
        "      precision = precision_score(Y_test, Y_pred_binary)\n",
        "      recall = recall_score(Y_test, Y_pred_binary)\n",
        "      f1 = f1_score(Y_test, Y_pred_binary)\n",
        "      mcc = matthews_corrcoef(Y_test, Y_pred_binary)\n",
        "      auc_roc = roc_auc_score(Y_test, Y_pred)\n",
        "\n",
        "      # Append the scores to the respective lists\n",
        "      accuracy_scores.append(accuracy)\n",
        "      precision_scores.append(precision)\n",
        "      recall_scores.append(recall)\n",
        "      f1_scores.append(f1)\n",
        "      mcc_scores.append(mcc)\n",
        "      auc_roc_scores.append(auc_roc)\n",
        "      fold_number += 1\n",
        "\n",
        "  # Calculate the average scores\n",
        "  avg_accuracy = np.mean(accuracy_scores)\n",
        "  avg_precision = np.mean(precision_scores)\n",
        "  avg_recall = np.mean(recall_scores)\n",
        "  avg_f1 = np.mean(f1_scores)\n",
        "  avg_mcc = np.mean(mcc_scores)\n",
        "  avg_auc_roc = np.mean(auc_roc_scores)\n",
        "\n",
        "  # Print the average scores\n",
        "  print(\"Average Test Accuracy:\", avg_accuracy)\n",
        "  print(\"Average Precision:\", avg_precision)\n",
        "  print(\"Average Recall:\", avg_recall)\n",
        "  print(\"Average F1 Score:\", avg_f1)\n",
        "  print(\"Average MCC:\", avg_mcc)\n",
        "  print(\"Average AUC-ROC:\", avg_auc_roc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whK7qRCe9LMJ",
        "outputId": "dbfc6ac8-7a24-47ab-e111-1dbe6eafbbfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying K-fold\n",
            "Applying 128 filters of size 5\n",
            "Fold 1/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 7ms/step\n",
            "Fold 2/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 3/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 4/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 5/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 6/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 7/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 8/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 4ms/step\n",
            "Fold 9/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 3ms/step\n",
            "Fold 10/10:\n",
            "Applying SE Block\n",
            "Applying SE Block\n",
            "Applying flatten layer\n",
            "Epoch 1/30\n",
            "Epoch 2/30\n",
            "Epoch 3/30\n",
            "Epoch 4/30\n",
            "Epoch 5/30\n",
            "Epoch 6/30\n",
            "Epoch 7/30\n",
            "Epoch 8/30\n",
            "Epoch 9/30\n",
            "Epoch 10/30\n",
            "Epoch 11/30\n",
            "Epoch 12/30\n",
            "Epoch 13/30\n",
            "Epoch 14/30\n",
            "Epoch 15/30\n",
            "Epoch 16/30\n",
            "Epoch 17/30\n",
            "Epoch 18/30\n",
            "Epoch 19/30\n",
            "Epoch 20/30\n",
            "Epoch 21/30\n",
            "Epoch 22/30\n",
            "Epoch 23/30\n",
            "Epoch 24/30\n",
            "Epoch 25/30\n",
            "Epoch 26/30\n",
            "Epoch 27/30\n",
            "Epoch 28/30\n",
            "Epoch 29/30\n",
            "Epoch 30/30\n",
            "20/20 [==============================] - 0s 5ms/step\n",
            "Average Test Accuracy: 0.9520863834176037\n",
            "Average Precision: 0.9525487619307296\n",
            "Average Recall: 0.9620398860398861\n",
            "Average F1 Score: 0.9571195297051949\n",
            "Average MCC: 0.9032611733702482\n",
            "Average AUC-ROC: 0.9826010966399854\n"
          ]
        }
      ],
      "source": [
        "kfold(filter_size, number_of_filter, flatten_layer_exist, Model_Name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
